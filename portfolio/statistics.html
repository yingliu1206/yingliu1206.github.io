<!DOCTYPE HTML>
<html>
	<head>
		<title>statistics</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<style>
            body {
                font-family: Arial, sans-serif;
                margin: 0;
                padding: 0;
                color: #333;
                background-color: #f4f4f4;
            }
            .container {
                max-width: 1200px;
                margin: 20px auto;
                padding: 20px;
                background-color: #fff;
                border-radius: 8px;
                box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            }
            h1, h2 {
                color: #333;
            }
            ul {
                list-style-type: disc;
                margin-left: 20px;
            }
            .section {
                margin-bottom: 20px;
            }
            .section h2 {
                border-bottom: 2px solid #333;
                padding-bottom: 5px;
            }
            .compact-list ul {
                margin-bottom: 0; /* Reduce or remove the space below the inner list */
                padding-bottom: 0; /* Remove any padding from the bottom */
            }
            .highlight {
            color: red; /* Highlight color */
            font-weight: bold;
            }
            .image-container {
            text-align: left;
            margin: 5px 0;
            flex-wrap: wrap;
            gap: 10px; /* Adjust the spacing between images as needed */
            }
            .image-container img {
                max-width: 48%;
                height: auto;
            }
        </style>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<!-- <a href="education.html" class="logo"><strong>Editorial</strong> by HTML5 UP</a> -->
									<ul class="icons">
										<!-- <li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon brands fa-snapchat-ghost"><span class="label">Snapchat</span></a></li> -->
										<li><a href="https://www.linkedin.com/in/ying-liu-4b45a8195/" class="icon brands fa-linkedin" style="font-size:1.5em"><span class="label">LinkedIn</span></a></li>
										<li><a href="https://github.com/yingliu1206" class="icon brands fa-github" style="font-size:1.5em"><span class="label">GitHub</span></a></li>
									</ul>
								</header>

							<!-- Content -->
								<section>
                                    <div class="container">
                                        <h1>Statistics</h1>                                      
                                        
                                        <div class="section">
                                            <h2>Statistics Measures</h2>
                                            <ul class="compact-list">
                                                <li><strong>Mean:</strong> The mean is a measure of central tendency, calculated as the sum of all values divided by the number of values. It can be significantly influenced by extremely high or low values in the dataset.</li>
                                                <li><strong>Median:</strong> The median represents the middle value when the data is sorted in ascending order. It is less affected by outliers compared to the mean.</li>
                                                <li><strong>Mode:</strong> The mode is the value that appears most frequently in the dataset.</li>
                                                <li><strong>Mean Absolute Deviation:</strong> The mean absolute deviation of a dataset is the average distance between each data point and the mean. It gives us an idea about the <span class="highlight">variability in a dataset</span>.</li>
                                                <div class="image-container">
                                                    <img src="images/mad.png" alt="MAD" style="max-width: 22%">
                                                </div>
                                                <li><strong>Outliers:</strong> Outliers are values that differ significantly from other observations. In a normal distribution, outliers are often defined as values that fall outside the range of <span class="highlight">Q3 + 1.5 * IQR</span> or <span class="highlight">Q1 - 1.5 * IQR</span>.</li>
                                                <li>
                                                    <strong>Z-Score:</strong>
                                                    A z-score measures exactly how many standard deviations above or below the mean a data point is. We can determine thresholds (e.g., 2, 2.5, 3) to decide on outliers.
                                                    <ul>
                                                        <li>Z-scores can be applied to all distributions, not just normal distributions.</li>
                                                    </ul>
                                                </li>
                                                <li><strong>Interquartile Range (IQR):</strong> The IQR is the range between the first quartile (Q1) and the third quartile (Q3), encompassing the middle 50% of the data. It helps in identifying the spread and detecting outliers.</li>
                                                <!-- Visual Representation -->
                                                <div class="image-container">
                                                    <img src="images/IQR.png" alt="IQR">
                                                </div>
                                                
                                            </ul>
                                        </div>
                                        
                                        <div class="section">
                                            <h2>Visualizations</h2>
                                            <ul>
                                                <li><strong>Categorical Data:</strong> bar charts and two-way tables.</li>
                                                <li><strong>Histograms:</strong> A histogram displays numerical data by grouping it into bins of equal width. Each bin's height corresponds to the number of data points within that bin. Bins are also referred to as intervals, classes, or buckets.</li>
                                                <li><strong>Stem and Leaf Plots:</strong> This plot displays numerical data by splitting each data point into a leaf (usually the last digit) and a stem (the leading digit or digits).</li>
                                                <li><strong>Box Plot:</strong> A box plot shows the minimum, maximum, median, and interquartile range (IQR) of the data.</li>
                                                <li><strong>Line Graph:</strong> A line graph is useful for showing trends over time. It's important to be cautious about the scale used in the graph.</li>
                                                <li><strong>Scatterplot:</strong> Shows the relationship between two numerical variables. There is no standard rule for identifying outliers, but scatterplots are useful for visualizing correlations.</li>
                                                <li><strong>Cumulative Relative Frequency Graph:</strong> The Y-axis represents percentiles, showing the cumulative distribution of the data.</li>
                                                <div class="image-container">
                                                    <img src="images/cumulative relative frequency plot.png" alt="Cumulative Relative Frequency Graph">
                                                </div>
                                            </ul>
                                        </div>

                                        <div class="section">
                                            <h2>Sampling and Distributions</h2>
                                            <ul class="compact-list">
                                                <li>
                                                    <strong>Sampling:</strong> Selecting a subset from a population to estimate characteristics. Sampling methods can be:
                                                    <ul >
                                                        <li><strong>Probability-based:</strong> Each member of the population has a known probability of being selected.</li>
                                                        <li><strong>Non-probability based:</strong> Selection of individuals is based on convenience, judgment, or quota.</li>
                                                    </ul>
                                                </li>

                                                <li>
                                                    <strong>Distribution:</strong> Refers to the center and spread (variability) of data. When analyzing distributions, consider:
                                                    <ul>
                                                        <li><strong>Center:</strong> Typically described by the <strong>mean</strong> or <strong>median</strong>.</li>
                                                        <li><strong>Spread/Variability:</strong> Described by measures like the <strong>standard deviation (SD)</strong> or the <strong>interquartile range (IQR)</strong>.</li>
                                                        <li>
                                                            <strong>Shift:</strong> When adding a constant to each data point:
                                                            <ul>
                                                                <li><strong>Mean</strong> and <strong>median</strong> will change by the same constant.</li>
                                                                <li><strong>Standard deviation (SD)</strong> and <strong>interquartile range (IQR)</strong> will remain unchanged.</li>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            <strong>Scale:</strong> When multiplying each data point by a constant:
                                                            <ul>
                                                                <li><strong>Mean</strong>, <strong>median</strong>, <strong>SD</strong>, and <strong>IQR</strong> will all change by the same multiplication factor.</li>
                                                            </ul>
                                                        </li>
                                                        <div class="image-container">
                                                            <img src="images/density curve.png" alt="density curve">
                                                        </div>
                                                    </ul>
                                                </li>

                                                <li>
                                                    <strong>Central Limit Theorem:</strong> 
                                                    The central limit theorem states that if a random sample is drawn from any population, regardless of its distribution, <strong>the distribution of the sample means</strong> will be approximately normally distributed as the sample size increases.
                                                    <ul>
                                                        <li>This allows for inferences about a population based on a sample, even without knowing the population's distribution.</li>
                                                        <li>By using the central limit theorem, we can assume that the sample means will be normally distributed and use this information to perform hypothesis tests or construct confidence intervals.</li>
                                                    </ul>
                                                </li>

                                                <li>
                                                    <strong>Combining Random Variables:</strong>
                                                    <ul>
                                                        <li>
                                                            <strong>Effect on Mean and Variance:</strong>
                                                            When combining random variables, those that follow a normal distribution, the resulting distribution also follows a normal distribution. Here's how the mean, standard deviation, and variance are affected:
                                                            <div class="image-container">
                                                                <img src="images/combining random variables.png" alt="combining random variables">
                                                            </div>
                                                        </li>
                                                    </ul>
                                                </li>


                                                <li>
                                                    <strong>Normal Distribution:</strong> A type of probability distribution commonly observed in real-world phenomena such as heights, weights, or IQ scores.
                                                    <ul>
                                                        <li>Also known as a <strong>Gaussian distribution</strong> or a <strong>bell curve</strong> due to its shape.</li>
                                                        <li>The bell curve is defined by the <strong>mean</strong> and the <strong>standard deviation</strong>.</li>
                                                        <li>The <strong>68-95-99.7 rule</strong> explains the proportion of data that falls within specific standard deviations:
                                                            <ul>
                                                                <li>68% of the data are within one standard deviation of the mean.</li>
                                                                <li>95% of the data are within two standard deviations of the mean.</li>
                                                                <li>99.7% of the data are within three standard deviations of the mean.</li>
                                                            </ul>
                                                            <div class="image-container">
                                                                <img src="images/normal distribution.png" alt="normal distribution">
                                                            </div>
                                                        </li>
                                                    </ul>
                                                </li>

                                                <li>
                                                    <strong>Binomial Distribution:</strong>
                                                    <ul>
                                                        <li>
                                                            A binomial distribution describes the number of successes in a fixed number of independent trials of a binary (yes/no) experiment, each with the same probability of success.
                                                        </li>
                                                        <li>
                                                            <strong>Binomial Variable:</strong>
                                                            <div class="image-container">
                                                                <img src="images/binomial vairables.png" alt="Binomial Variables">
                                                            </div>
                                                        </li>
                                                        <li>
                                                            <strong>Probability Mass Function:</strong> The probability of getting exactly \( k \) successes in \( n \) trials is given by:
                                                            <br>
                                                            \( P(X = k) = C(n, k) \cdot p^k \cdot (1 - p)^{(n - k)} \)
                                                            <br>
                                                            where:
                                                            <ul>
                                                                <li>\( C(n, k) \) is the binomial coefficient (combinations).</li>
                                                                <li>\( p \) is the probability of success on a single trial.</li>
                                                                <li>\( n \) is the number of trials.</li>
                                                                <li>\( k \) is the number of successes.</li>
                                                                <li>Example:</li>
                                                                <div class="image-container">
                                                                    <img src="images/binomial distribution example.png" alt="Binomial Distribution Example">
                                                                </div>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            <strong>Mean and Variance:</strong>
                                                            <ul>
                                                                <li><strong>Mean:</strong> \( \mu = n \cdot p \)</li>
                                                                <li><strong>Variance:</strong> \( \sigma^2 = n \cdot p \cdot (1 - p) \)</li>
                                                            </ul>
                                                        </li>
                                                    </ul>
                                                </li>

                                                <li>
                                                    <strong>Bernoulli Distribution:</strong>
                                                    <ul>
                                                        <li>A Bernoulli distribution is a special case of the binomial distribution where the number of trials \( n \) is 1.</li>
                                                        <li>
                                                            <strong>Probability Mass Function:</strong> The probability of success in a single Bernoulli trial is given by:
                                                            <br>
                                                            \( P(X = 1) = p \)
                                                            <br>
                                                            \( P(X = 0) = 1 - p \)
                                                            <br>
                                                            where:
                                                            <ul>
                                                                <li>\( p \) is the probability of success.</li>
                                                                <li>\( 1 - p \) is the probability of failure.</li>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            <strong>Mean and Variance:</strong>
                                                            <ul>
                                                                <li><strong>Mean:</strong> \( \mu = p \)</li>
                                                                <li><strong>Variance:</strong> \( \sigma^2 = p \cdot (1 - p) \)</li>
                                                            </ul>
                                                        </li>
                                                    </ul>
                                                </li>

                                                <li>
                                                    <strong><span class="highlight">Using Population to Estimate Sample Characteristics:</span></strong>
                                                    <ul>
                                                        <ol>
                                                            <li>
                                                                <strong>Sample Proportion Distribution:</strong>
                                                                <ul>
                                                                    <li>The distribution of sample proportions is approximately normal if:
                                                                        <ul>
                                                                            <li>The expected number of successes and failures is at least 10 (i.e., &#1109;p &#8805; 10 and &#1109;(1 - p) &#8805; 10).</li>
                                                                            <li>The sample size is ≤ 10% of the population, or sampling is done with replacement to ensure independence.</li>
                                                                        </ul>
                                                                    </li>
                                                                    <li>Sample Mean = \( p \) (the population proportion)</li>
                                                                    <li>Sample Variance = \( \frac{p \cdot (1 - p)}{n} \)</li>
                                                                </ul>
                                                            </li>
                                                            <li>
                                                                <strong>Sample Mean Distribution:</strong>
                                                                <ul>
                                                                    <li>The distribution of sample means is approximately normal if:
                                                                        <ul>
                                                                            <li>The sample size is sufficiently large (≥ 30). For smaller sample sizes (< 30), the distribution approximates the population distribution if the population distribution is normal.</li>
                                                                        </ul>
                                                                    </li>
                                                                    <li>Sample Mean = &#956; (the population mean) .</li>
                                                                    <li>Sample Variance = &#966;&#8322;/n (where &#966;&#8322; is the population variance).</li>
                                                                </ul>
                                                            </li>
                                                            <li>
                                                                <strong>Example:</strong>
                                                                <div class="image-container">
                                                                    <img src="images/population_sample_example.png" alt="Population to Sample Example">
                                                                </div>
                                                            </li>
                                                        </ol>
                                                    </ul>
                                                </li>
                                                
                                        </div>
                                    
                                        <div class="section">
                                            <h2>Inference and Testing</h2>
                                            <ul class="compact-list">
                                                <li>
                                                    <strong>Confidence Intervals:</strong> A range within which a population parameter is likely to fall.
                                                    <ul>
                                                        <li>
                                                            <strong>Confidence Interval for Means (n ≥ 30): <span class="highlight">\( \bar{x} \pm z \cdot \frac{\sigma}{\sqrt{n}} \)</span></strong>
                                                            where:
                                                            <ul>
                                                                <li>\(\bar{x}\) is the sample mean.</li>
                                                                <li>\(z\) is the z-score corresponding to the desired confidence level.</li>
                                                                <li>\(\sigma\) is the population standard deviation (or sample standard deviation if \(\sigma\) is unknown).</li>
                                                                <li>\(n\) is the sample size.</li>
                                                            </ul>
                                                            <ul>
                                                                <li>
                                                                    <strong>Conditions for Inference on a Mean:</strong>
                                                                    <ul>
                                                                        <li><strong>Random:</strong> A random sample or randomized experiment should be used to obtain the data.</li>
                                                                        <li><strong>Normal:</strong> The sampling distribution of the sample mean needs to be approximately normal. This is true if:
                                                                            <ul>
                                                                                <li>The parent population is normal,</li>
                                                                                <li>or the sample size is reasonably large (n ≥ 30),</li>
                                                                                <li>or the sample distribution is roughly symmetric with no outliers.</li>
                                                                            </ul>
                                                                        </li>
                                                                        <li><strong>Independent:</strong>If sampling without replacement, the sample size should be less than 10% of the population.</li>
                                                                    </ul>
                                                                </li>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            <strong>Confidence Interval for Means (n < 30): <span class="highlight">\( \bar{x} \pm t \cdot \frac{s}{\sqrt{n}} \)</span></strong>
                                                            where:
                                                            <ul>
                                                                <li>\(\bar{x}\) is the sample mean.</li>
                                                                <li>\(t\) is the t-score from the t-distribution corresponding to the desired confidence level and degrees of freedom (\(n-1\)).</li>
                                                                <li>\(s\) is the sample standard deviation.</li>
                                                                <li>\(n\) is the sample size.</li>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            <strong>Confidence Interval for Proportions: <span class="highlight">\( \hat{p} \pm z \cdot \sqrt{\frac{\hat{p} \cdot (1 - \hat{p})}{n}} \)</span></strong>
                                                            where:
                                                            <ul>
                                                                <li>\(\hat{p}\) is the sample proportion.</li>
                                                                <li>\(z\) is the z-score corresponding to the desired confidence level.</li>
                                                                <li>\(n\) is the sample size.</li>
                                                            </ul>
                                                            <ul>
                                                                <li>
                                                                    <strong>Conditions for Inference on a Proportion:</strong>
                                                                    <ul>
                                                                        <li><strong>Random:</strong> The data needs to come from a random sample or randomized experiment.</li>
                                                                        <li><strong>Normal:</strong> At least 10 expected successes and 10 expected failures.</li>
                                                                        <li><strong>Independent:</strong> If sampling without replacement, the sample size should be less than 10% of the population.</li>
                                                                    </ul>
                                                                </li>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            <strong>Confidence Interval for the Mean Difference of Paired Data: <span class="highlight">\( \bar{d} \pm t \cdot \frac{s_d}{\sqrt{n}} \)</span></strong>
                                                            where:
                                                            <ul>
                                                                <li>\(\bar{d}\) is the mean difference between paired observations.</li>
                                                                <li>\(t\) is the t-score from the t-distribution corresponding to the desired confidence level and degrees of freedom (\(n-1\)).</li>
                                                                <li>\(s_d\) is the sample standard deviation of the differences.</li>
                                                                <li>\(n\) is the number of paired observations.</li>
                                                            </ul>
                                                        </li>
                                                    </ul>
                                                </li>
                                                
                                                <li><strong>Z Statistic vs T Statistic:</strong> The number of standard errors is used to calculate the statistic based on the confidence level. The Z statistic is used for large sample sizes or known population standard deviation, while the T statistic is used for smaller samples or unknown population standard deviation.</li>
                                                <ul>
                                                    <li><strong>Z Statistic:</strong> 
                                                        <span class="highlight">\( Z = \frac{\bar{x} - \mu}{\frac{\sigma}{\sqrt{n}}} \)</span>
                                                        <ul>
                                                            <li>\(\bar{x}\) is the sample mean.</li>
                                                            <li>\(\mu\) is the population mean.</li>
                                                            <li>\(\sigma\) is the population standard deviation.</li>
                                                            <li>\(n\) is the sample size.</li>
                                                        </ul>
                                                    </li>
                                                    <li><strong>T Statistic:</strong> 
                                                        <span class="highlight">\( T = \frac{\bar{x} - \mu}{\frac{s}{\sqrt{n}}} \) (\(df = n - 1\))</span>
                                                        <ul>
                                                            <li>\(\bar{x}\) is the sample mean.</li>
                                                            <li>\(\mu\) is the population mean.</li>
                                                            <li>\(s\) is the sample standard deviation.</li>
                                                            <li>\(n\) is the sample size.</li>
                                                        </ul>
                                                    </li>
                                                    <li><strong>Selection:</strong> 
                                                        <div class="image-container">
                                                            <img src="images/Test-statistic.png" alt="Test Statistic">
                                                        </div>
                                                    </li>
                                                </ul>
                                                
                                                <li>
                                                    <strong>Hypothesis Testing:</strong>
                                                    <ul>
                                                        <li>
                                                            Hypothesis testing is a method in which a sample dataset is compared against the population data. <strong><span class="highlight">Using Sample to Estimate Population Characteristics:</span></strong>
                                                        </li>
                                                        <li>
                                                            <strong>Steps for performing a hypothesis test:</strong>
                                                            <ul>
                                                                <li>
                                                                    <strong>State your null and alternative hypotheses:</strong> The null hypothesis (H<sub>0</sub>) generally assumes no change, while the alternative hypothesis (H<sub>a</sub>) suggests a deviation from the null hypothesis.
                                                                </li>
                                                                <li>
                                                                    <strong>Set your significance level (α):</strong> Typically set at 5% (α = 0.05), but it can vary depending on the severity of Type I (false positive) and Type II (false negative) errors in the situation.
                                                                </li>
                                                                <li>
                                                                    <strong>Collect sample data and calculate sample statistics:</strong> Use the Z-statistic or T-statistic based on the sample size and distribution of the data.
                                                                </li>
                                                                <li>
                                                                    <strong>Calculate the p-value:</strong> The p-value is derived from the sample statistics and indicates the likelihood of observing the data under the null hypothesis. Common approaches are based on T-scores and Z-scores for normal distributions.
                                                                </li>
                                                                <li>
                                                                    <strong>Make a decision:</strong> Based on the p-value, reject or do not reject the null hypothesis. If the p-value is less than the significance level, reject the null hypothesis.
                                                                </li>
                                                                <li>
                                                                    <strong>Statistical Significance:</strong> 
                                                                    <ul>
                                                                        <li>If \( P < \alpha \), then the result is considered statistically significant.</li>
                                                                    </ul>
                                                                </li>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            <strong>Type I and Type II Errors:</strong>
                                                            <ul>
                                                                <li>
                                                                    <strong>Type I Error:</strong> Occurs when we reject the null hypothesis when it is actually true.
                                                                    <ul>
                                                                        <li>Also known as a "false positive."</li>
                                                                        <li>The probability of making a Type I error is denoted by alpha (α), which is the significance level of the test.</li>
                                                                    </ul>
                                                                </li>
                                                                <li>
                                                                    <strong>Type II Error:</strong> Occurs when we fail to reject the null hypothesis when it is actually false.
                                                                    <ul>
                                                                        <li>Also known as a "false negative."</li>
                                                                        <li>The probability of making a Type II error is denoted by beta (β).</li>
                                                                    </ul>
                                                                </li>
                                                            </ul>
                                                        </li>
                                                        
                                                        <li>
                                                            <strong>Power of a Test:</strong>
                                                            <ul>
                                                                <li>Power = P(not making a Type II error)</li>
                                                                <li>
                                                                    A higher power reduces the likelihood of committing a Type II error (failing to reject a false null hypothesis).
                                                                </li>
                                                                <li>
                                                                    <strong>Methods to increase power:</strong>
                                                                    <ul>
                                                                        <li>Increase the sample size.</li>
                                                                        <li>Increase the significance level α. <em>(Note: this may increase the risk of a Type I error)</em></li>
                                                                        <li>Reduce variability in the data (control experimental conditions).</li>
                                                                        <li>Choose a larger effect size (the difference between the null and alternative hypotheses).</li>
                                                                    </ul>
                                                                </li>
                                                            </ul>
                                                        </li>

                                                        <li>
                                                            <strong>Example 1:</strong> Calculating the Z test and p-value for a proportion:
                                                            <div class="image-container">
                                                                <img src="images/z test example.png" alt="Z test example">
                                                            </div>
                                                        </li>
                                                        
                                                        <li>
                                                            <strong>Example 2:</strong> Calculating the t test and p-value for a mean:
                                                            <div class="image-container">
                                                                <img src="images/t test example.png" alt="T test example">
                                                            </div>
                                                        </li>
                                                        
                                                        <li>
                                                            <strong>Example 3:</strong> Two-sample inference for the difference between groups:
                                                            <ul>
                                                                <li>Mean of Sample 1: <em>mean<sub>P1</sub></em>, Variance of Sample 1: <em>var<sub>P1</sub></em></li>
                                                                <li>Mean of Sample 2: <em>mean<sub>P2</sub></em>, Variance of Sample 2: <em>var<sub>P2</sub></em></li>
                                                                <li>Mean of the Difference: \( \text{mean}_{\text{diff}} = \text{mean}_{\text{P1}} - \text{mean}_{\text{P2}} \)</li>
                                                                <li>Variance of the Difference: \( \text{var}_{\text{diff}} = \text{var}_{\text{P1}} + \text{var}_{\text{P2}} \)</li>
                                                            </ul>
                                                            <div class="image-container">
                                                                <img src="images/two-sample1.png" alt="Two-sample inference for the difference between groups">
                                                                <img src="images/two-sample2.png" alt="Two-sample inference for the difference between groups">
                                                            </div>
                                                            <div class="image-container">
                                                                <img src="images/two-sample3.png" alt="Two-sample inference for the difference between groups">
                                                                <img src="images/two-sample4.png" alt="Two-sample inference for the difference between groups">
                                                            </div>
                                                            <div class="image-container">
                                                                <img src="images/two-sample5.png" alt="Two-sample inference for the difference between groups">
                                                                <img src="images/two-sample6.png" alt="Two-sample inference for the difference between groups">
                                                            </div>
                                                        </li>                                   

                                                    </ul>
                                                </li>

                                                <li><strong>Chi-Square Testing</strong>
                                                    <ul>
                                                        <li>
                                                            <strong>Chi-Square Distribution:</strong>
                                                            A chi-square statistic measures the difference between observed and expected frequencies in categorical variables. It is useful for analyzing differences in nominal categorical variables.
                                                            <div class="example">
                                                                <strong>Example Probability:</strong>
                                                                <code>P(Q<sub>2</sub> &gt; 2.41) = 0.3</code>
                                                                <div class="image-container">
                                                                    <img src="images/chi-square distribution.png" alt="Chi-Square Distribution">
                                                                    <img src="images/chi-square distribution2.png" alt="Chi-Square Distribution">
                                                                </div>
                                                            </div>
                                                            
                                                        </li>

                                                        <li><strong>Conditions for Inference:</strong>
                                                            <ul>
                                                                <li><strong>Random:</strong> A random sample or randomized experiment should be used to obtain the data.</li>
                                                                <li><strong>Normal:</strong> The expected number of each category outcome should be ≥ 5.</li>
                                                                <li><strong>Independent:</strong> The sample size should be less than 10% of the population if sampling without replacement.</li>
                                                            </ul>
                                                        </li>

                                                        <li><strong>Types of Chi-Square Tests:</strong>
                                                            <ul>
                                                                <ol>
                                                                    <li><strong>Pearson's Chi-Square Test (Goodness of Fit):</strong> Assesses how well the observed frequencies fit the expected frequencies.</li>
                                                                    <ul>
                                                                        <li>
                                                                            <div class="example">
                                                                                <strong>Example:</strong>
                                                                                <div class="image-container">
                                                                                    <img src="images/pearson's chi-square.png" alt="Design a Chi-Square Test">
                                                                                </div>
                                                                            </div>                                                            
                                                                        </li> 
                                                                    </ul>
                                                                    <li><strong>Test for Association (Independence):</strong> Evaluates the association between two variables within the same population.</li>
                                                                    <ul>
                                                                        <li>
                                                                            <div class="example">
                                                                                <strong>Example:</strong><br>
                                                                                - Sample: Measure foot and hand length in the same population<br>
                                                                                - Hypotheses:<br>
                                                                                - <code>H<sub>0</sub></code>: No association between foot and hand length (independent).<br>
                                                                                - <code>H<sub>a</sub></code>: There is an association.</p>
                                                                                <div class="image-container">
                                                                                    <img src="images/chi-square-association.png" alt="Chi-Square Test for Association">
                                                                                </div>
                                                                            </div>                                                            
                                                                        </li> 
                                                                    </ul>
                                                                    <li><strong>Test for Homogeneity:</strong> Compares distributions across different populations.</li>
                                                                    <ul>
                                                                        <li>
                                                                            <div class="example">
                                                                                <strong>Example:</strong><br>
                                                                                - Sample: 20 left-handed and 30 right-handed individuals<br>
                                                                                - Hypotheses:<br>
                                                                                - <code>H<sub>0</sub></code>: No difference in subject preference between left and right-handed individuals.<br>
                                                                                - <code>H<sub>a</sub></code>: There is a difference.</p>
                                                                                <div class="image-container">
                                                                                    <img src="images/chi-square-homo.png" alt="Chi-Square Test for Homogeneity">
                                                                                </div>
                                                                            </div>                                                            
                                                                        </li> 
                                                                    </ul>
                                                                </ol>
                                                            </ul>
                                                        </li>

                                                        <li>
                                                            <strong>Filling out frequency table for independent events</strong>
                                                            <div class="image-container">
                                                                <img src="images/fill_out_frequency_table.png" alt="Filling out frequency tablefor independent events">
                                                            </div>
                                                        </li>
                                                        
                                                        <li>
                                                            <strong>Degrees of Freedom:</strong>
                                                            <p><code>Degrees of Freedom = (Number of Columns - 1) × (Number of Rows - 1)</code></p>
                                                        </li>

                                                    </ul>
                                                </li>

                                                <li><strong>ANOVA (Analysis of Variance):</strong> Compares means of three or more groups to determine significant differences.</li>
                                                <ul>
                                                    <li>
                                                        <div class="example">
                                                            <strong>Example 1: Testing Food Preferences</strong><br>
                                                            Let's say we want to test if three different types of food (1, 2, and 3) have different effects on a preference score. We have the following:<br>
                                                            <ul>
                                                                <li><strong>M:</strong> Number of groups (3)</li>
                                                                <li><strong>N:</strong> Number of elements in each group</li>
                                                            </ul>

                                                            <ul>
                                                                <ol>
                                                                    <li>
                                                                        <strong>Calculate SST (Total Sum of Squares)</strong><br>
                                                                                Degrees of freedom: <code>M*N - 1</code>
                                                                                <div class="image-container">
                                                                                    <img src="images/anova1.png" alt="Testing Food Preferences">
                                                                                </div>
                                                                    </li>

                                                                    <li>
                                                                        <strong>Calculate SSW (Sum of Squares Within) and SSB (Sum of Squares Between)</strong><br>
                                                                                Figure out how much SST is caused by the variance within the group and between the groups:
                                                                                <ul>
                                                                                    <li><strong>SSW:</strong> Sum of squares within the group, Degrees of freedom: <code>M*(N-1)</code></li>
                                                                                    <li><strong>SSB:</strong> Sum of squares between the groups, Degrees of freedom: <code>M-1</code></li>
                                                                                </ul>
                                                                                <div class="image-container">
                                                                                    <img src="images/anova-ssw.png" alt="Testing Food Preferences">
                                                                                    <img src="images/anova-ssb.png" alt="Testing Food Preferences">
                                                                                </div>
                                                                    </li>

                                                                    <li>
                                                                        <strong>According to the formula: <code>SST = SSW + SSB</code></strong><br>
                                                                        <div class="image-container">
                                                                            <img src="images/anova-sst.png" alt="Testing Food Preferences">
                                                                        </div>
                                                                    </li>

                                                                    <li><strong>Hypothesis test:</strong> 
                                                                        <ul>
                                                                            <li><code>H<sub>0</sub></code>: Food does not make a difference: <code>μ1 = μ2 = μ3</code></li>
                                                                            <li><code>H<sub>a</sub></code>: There is a difference</li>
                                                                            <li><strong>α:</strong> 0.10</li>
                                                                        </ul>
                                                                    </li>

                                                                    <li><strong>Calculate the F-statistic:</strong> 
                                                                        <div class="image-container">
                                                                            <img src="images/anova-F.png" alt="Testing Food Preferences">
                                                                        </div>
                                                                        <ul>
                                                                            <li>If the numerator is larger (variance between groups is larger), <code>H<sub>a</sub></code> is more likely to be true, and <code>F</code> is larger.</li>
                                                                            <li>If the denominator is larger (variance within groups is larger), it is harder to reject <code>H<sub>0</sub></code>, and <code>F</code> is smaller.</li>
                                                                        </ul>
                                                                    </li>

                                                                    <li><strong>Conclusion:</strong> 
                                                                        <div class="image-container">
                                                                            <img src="images/anova-f2.png" alt="Testing Food Preferences">
                                                                        </div>
                                                                        <div class="image-container">
                                                                            <img src="images/anova-f3.png" alt="Testing Food Preferences">
                                                                        </div>
                                                                        <ul>
                                                                            <li>Both the denominator and numerator follow a Chi-square distribution.</li>
                                                                            <li>Suppose the F-statistic calculated is 3.46 and the critical value is 12. We have enough evidence to reject <code>H0</code>.</li>
                                                                        </ul>
                                                                    </li>

                                                                </ol>
                                                            </ul>
                                                        </div>                                                            
                                                    </li> 
                                            
                                                    <li>
                                                        <strong>Example 2: Species Comparison</strong><br>
                                                        <strong>Distribution of Petal Length by Species:</strong><br>
                                                        <p>In this example, we performed an ANOVA test in Python to analyze the differences in the petal length of three different species of iris: setosa, versicolor, and virginica.</p>
                                                        <p>We loaded the iris dataset using the seaborn library, which contains information about the petal length, width, and other variables for each species of iris. We separated each species' petal length data into three sets: <code>setosa_petal_length</code>, <code>versicolor_petal_length</code>, and <code>virginica_petal_length</code>. The ANOVA test was performed using the <code>f_oneway()</code> function from the <code>scipy.stats</code> library, which provided the F-statistic and p-value.</p>
                                            
                                                        <p><strong>Here is the code:</strong></p>
                                                        <pre><code>from scipy.stats import f_oneway
import seaborn as sns

# load the 'iris' dataset
iris = sns.load_dataset('iris')

# perform the ANOVA test
setosa_petal_length = iris[iris['species'] == 'setosa']['petal_length']
versicolor_petal_length = iris[iris['species'] == 'versicolor']['petal_length']
virginica_petal_length = iris[iris['species'] == 'virginica']['petal_length']

f_statistic, p_value = f_oneway(setosa_petal_length, versicolor_petal_length, virginica_petal_length)

# print the results
print('F-statistic:', f_statistic)
print('p-value:', p_value)</code></pre>
                                            
                                                        <p><strong>Output Example:</strong></p>
                                                        <pre><code>F-statistic: 1180.16
p-value: 2.86e-91</code></pre>
                                                        <p>The resulting F-statistic was 1180.16, indicating a significant difference between the means of the petal length for the three species. The p-value was 2.86e-91, a very small value close to zero, indicating that the probability of observing such a large F-statistic by chance alone is very low. Therefore, we reject the null hypothesis that there is no significant difference between the means of petal length for the three species. We conclude that there is a significant difference between the means of petal length for at least one pair of species.</p>
                                                    </li>
                                                </ul>
                                            </ul>
                                        </div>

                                        <div class="section">
                                            <h2>A/B Testing</h2>
                                            A/B testing is an experiment comparing two variants to determine which performs better based on a given metric. It is essentially a form of two-sample hypothesis testing used to assess whether the differences between two samples are statistically significant.
                                            <ul class="compact-list">
                                                <li>
                                                    <strong>Steps to Conduct an A/B Test:</strong>
                                                    <ul>
                                                        <li>State the null and alternative hypotheses.</li>
                                                        <li>Set the significance level (α).</li>
                                                        <li>Collect sample data and calculate the sample statistics.</li>
                                                        <li>Calculate the p-value according to the type of A/B test.</li>
                                                        <li>Compare the p-value to the significance level to determine whether to reject the null hypothesis.</li>
                                                    </ul>
                                                </li>
                                                <li>
                                                    <strong>Choosing the Right Metric:</strong> The metric should be relevant to the test goal. Common metrics include conversion rate, click-through rate, or revenue.
                                                </li>
                                                <li>
                                                    <strong>Defining Hypotheses:</strong> Clearly specify the null and alternative hypotheses and set the significance level before conducting the test.
                                                </li>
                                                <li>
                                                    <strong>Sample Size Considerations:</strong> The sample size should be large enough to detect a meaningful difference but manageable in terms of cost and time. Factors to consider include expected effect size, significance level, and statistical power.
                                                </li>
                                                <li>
                                                    <strong>Real-Life Applications:</strong> A/B testing can be applied in various scenarios, such as:
                                                    <ul>
                                                        <li>A software company testing two feature versions to measure user engagement.</li>
                                                        <li>A fashion retailer comparing two product descriptions to determine which leads to more sales.</li>
                                                        <li>An e-commerce platform evaluating two checkout processes to see which results in more completed orders.</li>
                                                    </ul>
                                                </li>
                                                <li>
                                                    <strong>In-depth understanding:</strong> <a href="https://towardsdatascience.com/a-b-testing-a-complete-guide-to-statistical-testing-e3f1db140499" target="_blank">Francesco’s article on A/B testing</a>.
                                                </li>
                                                <li>
                                                    <strong>Methods:</strong> 
                                                    <ul>
                                                        <ol>
                                                            <li>
                                                                <strong>Fisher’s Exact Test:</strong> This test is used for discrete metrics like clickthrough rates (1 for yes, 0 for no). It computes the exact p-value, though it can be computationally expensive for large sample sizes.
                                                            
                                                                <div class="example">
                                                                    <strong>Example: Advertising Campaign</strong>
                                                                    <p>Suppose you're a marketing researcher testing a new advertising campaign's effectiveness. You randomly assign website visitors to see either the new or old ads and record their clickthrough rates. Fisher's test can help determine if the new ads are significantly more effective in increasing clickthrough rates compared to the old ads.</p>
                                                                </div>
                                                            </li>
                                                            
                                                            <li>
                                                                <strong>Pearson’s Chi-squared Test:</strong> This test is an alternative to Fisher’s test for <u>large sample sizes</u> and is used for discrete metrics.
                                                                <div class="example">
                                                                    <strong>Example: Marketing Research</strong>
                                                                    <p>Consider a company that wants to explore the relationship between customer age groups (young, middle-aged, elderly) and their preferred product categories (food, clothing, electronics). They collect data from 500 customers and use Pearson's Chi-squared test to see if there is a significant association between age and product preference.</p>
                                                                </div>
                                                            </li>
                                                            
                                                            <li>
                                                                <strong>Student’s t-test:</strong> Used when the <u>sample size is large or the population standard deviation is unknown</u>. Suitable for comparing means when the samples have similar variances.
                                                            
                                                                <div class="example">
                                                                    <strong>Example: Teaching Method Testing</strong>
                                                                    <p>A study comparing the effectiveness of two teaching methods involves two groups of students. Each group receives a different method, and their test scores are compared using Student's t-test to determine if the new method significantly improves scores over the traditional method.</p>
                                                                </div>
                                                            </li>
                                                            
                                                            <li>
                                                                <strong>Welch’s Test:</strong> A variant of the Student’s t-test used when the two samples have <u>unequal variances</u>.
                                                            
                                                                <div class="example">
                                                                    <strong>Example: Salary Testing</strong>
                                                                    <p>To compare salaries between managers and entry-level employees, researchers use Welch’s t-test because the salaries' variability differs between the two groups. This test helps determine if there's a significant salary gap despite the unequal variances.</p>
                                                                </div>
                                                            </li>
                                                            
                                                            <li>
                                                                <strong>Mann-Whitney U Test:</strong> A non-parametric test used when assumptions for other tests (e.g., normality) are violated. Suitable for <u>small sample sizes and non-normal distributions</u>.
                                                            
                                                                <div class="example">
                                                                    <strong>Example: Medication Testing</strong>
                                                                    <p>In a study comparing the effectiveness of two pain medications with non-normally distributed data, the Mann-Whitney U test is used. Patients rate their pain after taking each medication, and the test helps determine if there is a significant difference in pain relief between the two treatments without assuming normality.</p>
                                                                </div>
                                                            </li>
                                                            
                                                            <li>
                                                                <strong>For more details on how to conduct these tests in Python, check out this <a href="https://github.com/FrancescoCasalegno/AB-Testing/blob/main/AB_Testing.ipynb" target="_blank">repository</a>.</strong>
                                                            </li>
                                                        </ol>
                                                    </ul>
                                                </li>

                                            </ul>
                                        </div>
                                    
                                        <div class="section">
                                            <h2>Relationships and Models</h2>
                                            <ul class="compact-list">
                                                <li><strong>Cosine Similarity:</strong> Cosine similarity is a way to measure how similar two sets of things are. The more similar the two sets of things are, the closer they are to each other in this space. The cosine similarity is calculated by looking at the angle between the two sets of things. If the angle is 0 degrees, that means they are exactly the same. If the angle is 90 degrees, that means they are completely different.
                                                    <div class="image-container">
                                                        <img src="images/cosine.png" alt="Cosine Similarity">
                                                    </div>
                                                    <strong>Example: Collaborative Filtering in Netflix</strong><br>
                                                    Collaborative filtering often uses cosine similarity to measure the similarity between items or users in a recommendation system. A real-life example of collaborative filtering is the recommendation system used by Netflix. Netflix uses collaborative filtering to recommend movies and TV shows to its users based on their viewing history and the viewing history of similar users. When a user watches a movie or TV show, the system analyzes the user's viewing history and compares it to others with similar viewing histories. Based on this, Netflix recommends other movies and TV shows that the user might enjoy.
                                                </li>

                                                <li><strong>Correlation:</strong> 
                                                    Correlation is a statistical measure that analyzes the strength of the relationship between two variables. It ranges from -1 to 1:
                                                    <div class="image-container">
                                                        <img src="images/correlation.png" alt="Correlation">
                                                    </div>
                                                    <ul>
                                                        <li>A value of -1 indicates a <strong>perfect negative correlation</strong>.</li>
                                                        <li>A value of 0 indicates <strong>no correlation</strong>.</li>
                                                        <li>A value of 1 indicates a <strong>perfect positive correlation</strong>.</li>
                                                    </ul>
                                                    While correlation does not imply causation, it can help identify potential relationships between variables.
                                                    <br>
                                                    <strong>Note:</strong> Correlation describes the relationship between variables, whereas causation occurs when one event is the direct result of another.
                                                    <div class="image-container">
                                                        <img src="images/CorrelationvsCausation.png" alt="Correlation vs Causation">
                                                    </div>
                                                </li>

                                                <li><strong>Linear Regression:</strong> 
                                                    Linear regression uses a line to summarize the relationship between one or more independent variables (x) and a dependent variable (y). It finds the 'line of best fit' by minimizing the squared distances between the points and the line, known as least squares regression. <br>
                                                    <ul class="compact-list">
                                                        <li><strong>Key Concepts:</strong></li>
                                                        <ul>
                                                            <li><strong>Slope:</strong> Δy / Δx</li>
                                                            <li><strong>Residual:</strong> y_actual - y_predicted</li>
                                                            <li><strong>Sum of Squared Residuals (SSR):</strong> The sum of the squared residuals</li>
                                                        </ul>

                                                        <li><strong>Steps to Calculate the Least Squares Regression Line:</strong>
                                                            <ul>
                                                                <li>Calculate the correlation coefficient.</li>
                                                                <div class="image-container">
                                                                    <img src="images/correlation coefficient.png" alt="Correlation Coefficient">
                                                                </div>
                                                                <li>Slope = <code>r * sd_y / sd_x</code>, where <code>r</code> is the correlation coefficient, <code>sd_y</code> is the standard deviation of the dependent variable, and <code>sd_x</code> is the standard deviation of the independent variable.</li>
                                                                <li>The model line must pass through <code>(x̄, ȳ)</code>, where <code>x̄</code> and <code>ȳ</code> are the means of the independent and dependent variables, respectively.</li>
                                                                <div class="image-container">
                                                                    <img src="images/linear regression.png" alt="Linear Regression">
                                                                </div>
                                                                <li>Two points must pass by the least squares regression line:</li>
                                                                <div class="image-container">
                                                                    <img src="images/two points in regression line.png" alt="Two points in Regression Line" style="max-width: 60%;">
                                                                </div>
                                                            </ul>
                                                        </li>

                                                        <li><strong>Covariance:</strong> <code>Cov(X, Y)</code>
                                                            <ul>
                                                                <li><strong>Slope:</strong> <code>Slope = Cov(X, Y) / Var(X)</code></li>
                                                            </ul>
                                                        </li>

                                                        <li><strong>Residual plot can evaluate the linear regression model:</strong>
                                                            <div class="image-container">
                                                                <img src="images/residual plot 1.png" alt="Residual Plot">
                                                            </div>
                                                                <ul>
                                                                    <li>If the points are evenly scattered → good model</li>
                                                                    <div class="image-container">
                                                                        <img src="images/residual plot2.png" alt="Residual Plot">
                                                                    </div>
                                                                    <li>If the points are not evenly scattered or far away from the x-axis or have a pattern → bad model → maybe it is a non-linear curve</li>
                                                                    <div class="image-container">
                                                                        <img src="images/residual plot3.png" alt="Residual Plot">
                                                                        <img src="images/residual plot4.png" alt="Residual Plot">
                                                                    </div>
                                                                </ul>
                                                        </li>

                                                        <li><strong>Variable Selection:</strong> Two common approaches for selecting variables are:
                                                            <ul>
                                                                <li><strong>Backward Elimination:</strong> Removing one variable at a time.</li>
                                                                <li><strong>Forward Selection:</strong> Adding one variable at a time.</li>
                                                            </ul>
                                                        You can evaluate a variable's significance in the model by its p-value (≤ 0.05 is generally considered significant).
                                                        </li>           

                                                        <li><strong>Model Evaluation:</strong>
                                                            <ul>
                                                                <li><strong>R-squared (coefficient of determination):</strong> Indicates what percentage of the variation in Y is described by the variation in X
                                                                    <ul>
                                                                        <li>Sum of Squared Residuals (SSR): The sum of residuals squared; <span class="highlight">measures the variance of Y that is not explained by the model.</span></li>
                                                                        <li>Total Sum of Squares (SST): The sum of squared <code>(y_i - &#772;y)</code>; <span class="highlight">measures the total variance of Y from its mean.</span></li>
                                                                        <li>Percentage of variation not described by X: <code>SSR / SST</code></li>
                                                                        <li><strong>R-squared = 1 - SSR / SST</strong></li>
                                                                        <li>SSR is small → R-squared is close to 1 → good model</li>
                                                                        <li>SSR is large → R-squared is close to 0 → bad model</li>
                                                                        <li>R-squared can also be calculated by <code>(Correlation coefficient)^2</code></li>
                                                                    </ul>
                                                                </li>
                                                                <li><strong>Adjusted R-squared: </strong> adjusts for the number of predictors in the model, increasing if the new term improves the model.</li>
                                                                <li><strong>Root-Mean-Square Error (RMSD):</strong> Sample standard deviation of residuals; represents typical prediction error. The lower the RMSD, the better the model.</li>
                                                                <div class="image-container">
                                                                    <img src="images/RMSD.png" alt="RMSD" style="max-width: 30%;">
                                                                </div>
                                                            </ul>
                                                        </li>

                                                        <li><strong>Common Pitfalls:</strong> 
                                                            <ul>
                                                                <li><strong>Overfitting:</strong> When the model fits the data too well, leading to high variance and low bias, which may result in poor predictions on new data.</li>
                                                                <li><strong>Collinearity:</strong> When two independent variables are highly correlated, reducing the model's accuracy.</li>
                                                                <li><strong>Confounding Variables:</strong> Variables that affect both the independent and dependent variables but are not included in the model.</li>
                                                            </ul>
                                                        </li>                                         
                                                    </ul>
                                                </li>

                                                <li><strong>Transforming:</strong>
                                                    <ul>
                                                        <li>If <code>X</code> and <code>y</code> have an exponential relationship, transform <code>y</code> with <code>log(y)</code>. This transformation can linearize the relationship between <code>X</code> and <code>y</code>.</li>
                                                        <li>This approach allows us to use linear regression techniques to analyze the data, such as hypothesis testing.</li>
                                                        <div class="image-container">
                                                            <img src="images/transforming.png" alt="Transforming" style="max-width: 55%;">
                                                        </div>
                                                        <li>The idea is to transform a non-linear relationship into a linear one, which simplifies the analysis, and then transform the results back to the original scale.</li>
                                                        <li><strong>Example:</strong></li>
                                                        <div class="image-container">
                                                            <img src="images/transforming example.png" alt="Transforming Example" style="max-width: 70%;">
                                                        </div>
                                                    </ul>
                                                </li>

                                            </ul>
                                        </div>

                                        <div class="section">
                                            <h2>Probability</h2>
                                                <h3>Probability Rules</h3>
                                                <ul>
                                                    <li>Every probability is between 0 and 1.</li>
                                                    <li>The sum of the probabilities of all possible outcomes equals 1.</li>
                                                    <li>If an event is impossible, it has a probability of 0.</li>
                                                    <li>Conversely, certain events have a probability of 1.</li>
                                                </ul>

                                                <h3>The Four Probability Rules</h3>
                                                <ul>
                                                    <ol>
                                                        <li><strong>Addition Rule</strong>
                                                            <ul>
                                                                <li>The addition rule in probability says that if there are two events, A and B, which cannot happen at the same time, then the probability of either event happening is equal to the total of their probabilities.</li>
                                                                <li>This means that if the events are independent, we can add their probabilities to calculate the overall probability of either event happening.</li>
                                                                <li>Formula: 
                                                                    <div class="image-container">
                                                                        <img src="images/Addition rule.png" alt="Addition Rule" style="max-width: 45%;">
                                                                    </div>
                                                                </li>
                                                                <li>Example: Consider a single toss of a fair coin. The probability of getting heads or tails is: <code>P(heads or tails) = 1/2 + 1/2 = 1</code></li>
                                                            </ul>
                                                        </li>
                                                        <li><strong>Complementary Rule</strong>
                                                            <ul>
                                                                <li>The complementary rule of probability says that when the probability of event A is represented by <code>p</code>, then the probability of event A not happening is represented by <code>1 - p</code>.</li>
                                                                <li>Formula: 
                                                                    <div class="image-container">
                                                                        <img src="images/Complementary rule.png" alt="Complementary Rule" style="max-width: 30%;">
                                                                    </div>
                                                                </li>
                                                                <li>Example: The probability of getting a 2 on a standard six-sided die is 1/6. The probability of getting other than 2 is: <code>P(not 2) = 1 - 1/6 = 5/6</code></li>
                                                            </ul>
                                                        </li>
                                                        <li><strong>Conditional Rule</strong>
                                                            <ul>
                                                                <li>Bayes theorem helps us calculate the conditional probability of the given events. Now let’s look at the formula and the example to make it clearer.</li>
                                                                <li>Formula: 
                                                                    <div class="image-container">
                                                                        <img src="images/Conditional rule.png" alt="Conditional Rule" style="max-width: 35%;">
                                                                    </div>
                                                                </li>
                                                                <li>Example: A medical test for a certain disease has a false positive rate of 5% and a false negative rate of 10%. If 1% of the population has the disease, what is the probability that a person who tests positive actually has the disease?</li>
                                                                <li>We can calculate the probability that a person who tests positive actually has the disease as follows:: 
                                                                    <div class="image-container">
                                                                        <img src="images/Conditional rule2.png" alt="Conditional Rule" style="max-width: 65%;">
                                                                    </div>
                                                                    <div class="image-container">
                                                                        <img src="images/conditional rule3.png" alt="Conditional Rule" style="max-width: 70%;">
                                                                    </div>
                                                                </li>
                                                            </ul>
                                                        </li>
                                                        <li><strong>Multiplication Rule</strong>
                                                            <ul>
                                                                <li>If events A and B are not related to each other, they are called independent events. In such cases, the probability of both events happening together is equal to the product of their individual probabilities.</li>
                                                                <li>Formula: 
                                                                    <div class="image-container">
                                                                        <img src="images/Multiplication rule.png" alt="Multiplication Rule">
                                                                    </div>
                                                                </li>
                                                                <li>Example: Let’s assume that you are drawing two cards from a standard deck of 52 cards. The probability of drawing an ace on the first draw is 4/52. The probability of drawing another ace on the second draw (assuming you did not replace the first card) is 3/51. The probability of drawing two aces is: <code>P(A and B) = 4/52 ⋅ 3/51 = 1/221</code></li>
                                                            </ul>
                                                        </li>
                                                    </ol>
                                                </ul>

                                                <h3>Bayes Theorem</h3>
                                                <ul class="compact-list">
                                                    <li>Bayes theorem is a conditional probability statement, essentially it looks at the probability of one event (B) happening given that another event (A) has already happened. The formula is as follows:</li>
                                                    <li>Formula: 
                                                        <div class="image-container">
                                                            <img src="images/Bayes1.png" alt="Bayes Theorem" style="max-width: 30%;">
                                                        </div>
                                                        <ul>
                                                            <li><code>P(A) is the prior, which is the probability of A being true.</code></li>
                                                            <li><code>P(B|A) is the likelihood, the probability of B being true given A.</code></li>
                                                            <li><code>P(B) is the marginalization or the normalizing constant.</code></li>
                                                            <li><code>P(A|B) is the posterior.</code></li>
                                                        </ul>
                                                    </li>
                                                    
                                                    <li>What you’ll find in a lot of practice problems is that the normalizing constant, <code>P(B)</code>, is not given. In these cases, you can use the alternative version of Bayes Theorem, which is below:</li>
                                                    <li>Formula: 
                                                        <div class="image-container">
                                                            <img src="images/Bayes2.png" alt="Bayes Theorem">
                                                        </div>
                                                    </li>
                                                </ul>

                                                <h3>Combinations and Permutations</h3>
                                                <p>Combinations and permutations are two slightly different ways that you can select objects from a set to form a subset. Permutations take into consideration the order of the subset whereas combinations do not.</p>
                                                <h4>Permutations</h4>
                                                <ul>
                                                    <li><strong>Definition:</strong> A permutation of <code>n</code> elements is any arrangement of those <code>n</code> elements in a definite order. There are <code>n!</code> ways to arrange <code>n</code> elements. Note the bold: order matters!</li>
                                                    <li>The number of permutations of <code>n</code> things taken <code>r</code>-at-a-time is defined as the number of <code>r</code>-tuples that can be taken from <code>n</code> different elements and is equal to the following equation:</li>
                                                    <li>Formula: <code>P(n, r) = n! / (n - r)!</code></li>
                                                    <li><strong>Example Question:</strong> How many permutations does a license plate have with 6 digits?</li>
                                                    <li>Answer: <code>P(9, 6) = 9! / (9 - 6)! = 60,480</code></li>
                                                </ul>
                                                <h4>Combinations</h4>
                                                <ul>
                                                    <li><strong>Definition:</strong> The number of ways to choose <code>r</code> out of <code>n</code> objects where order doesn’t matter.</li>
                                                    <li>The number of combinations of <code>n</code> things taken <code>r</code>-at-a-time is defined as the number of subsets with <code>r</code> elements of a set with <code>n</code> elements and is equal to the following equation:</li>
                                                    <li>Formula: <code>C(n, r) = n! / [(n - r)! r!]</code></li>
                                                    <li><strong>Example Question:</strong> How many ways can you draw 6 cards from a deck of 52 cards?</li>
                                                    <li>Answer: <code>C(52, 6) = 52! / [(52 - 6)! 6!] = 20,358,520</code></li>
                                                </ul>
                                        </div>
                                    

                                        <div class="section">
                                            <h2>Courses Attended</h2>
                                            <h3>Georgetown University (DSAN Program):</h3>
                                            <ul>
                                                <li>Probabilistic Modeling and Statistical Computing</li>
                                                <li>Statistical Learning</li>
                                            </ul>
                                            <h3>Khan Academy:</h3>
                                            <ul>
                                                <li>Statistics and Probability</li>
                                            </ul>
                                            <p><strong>Reference:</strong> <a href="https://www.stratascratch.com/blog/a-comprehensive-statistics-cheat-sheet-for-data-science-interviews/#probability_rules">StrataScratch: A Comprehensive Statistics Cheat Sheet for Data Science Interviews</a></p>
                                        </div>

                                    </div>
                                    
									
								</section>

						</div>
					</div>

                <!-- Sidebar -->
				<div id="sidebar-container"></div>
				
				<script>
					document.addEventListener("DOMContentLoaded", function() {
					  fetch('sidebar.html')
						.then(response => response.text())
						.then(data => {
						  document.getElementById('sidebar-container').innerHTML = data;
			  
						  // Load scripts after sidebar content is added
						  const scripts = [
							'assets/js/jquery.min.js',
							'assets/js/browser.min.js',
							'assets/js/breakpoints.min.js',
							'assets/js/util.js',
							'assets/js/main.js',
							'assets/js/search.js'
						  ];
			  
						  scripts.reduce((promise, script) => {
							return promise.then(() => {
							  return new Promise((resolve, reject) => {
								const s = document.createElement('script');
								s.src = script;
								s.onload = resolve;
								s.onerror = reject;
								document.body.appendChild(s);
							  });
							});
						  }, Promise.resolve())
						  .then(() => {
							console.log('All scripts loaded successfully.');
							// Ensure initialization of search after all scripts are loaded
							if (typeof window.initializeSearch === 'function') {
							  window.initializeSearch();
							}
						  })
						  .catch(error => {
							console.error('Error loading script:', error);
						  });
						})
						.catch(error => console.error('Error loading sidebar:', error));
					});
				</script>	
		</div>	

	</body>
</html>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
