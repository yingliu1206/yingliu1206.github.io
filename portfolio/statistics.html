<!DOCTYPE HTML>
<html>
	<head>
		<title>statistics</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<style>
            body {
                font-family: Arial, sans-serif;
                margin: 0;
                padding: 0;
                color: #333;
                background-color: #f4f4f4;
            }
            .container {
                max-width: 1200px;
                margin: 20px auto;
                padding: 20px;
                background-color: #fff;
                border-radius: 8px;
                box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            }
            h1, h2 {
                color: #333;
            }
            ul {
                list-style-type: disc;
                margin-left: 20px;
            }
            .section {
                margin-bottom: 20px;
            }
            .section h2 {
                border-bottom: 2px solid #333;
                padding-bottom: 5px;
            }
            .compact-list ul {
                margin-bottom: 0; /* Reduce or remove the space below the inner list */
                padding-bottom: 0; /* Remove any padding from the bottom */
            }
            .highlight {
            color: red; /* Highlight color */
            font-weight: bold;
            }
            .image-container {
            text-align: left;
            margin: 5px 0;
            flex-wrap: wrap;
            gap: 10px; /* Adjust the spacing between images as needed */
            }
            .image-container img {
                max-width: 48%;
                height: auto;
            }
        </style>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<!-- <a href="education.html" class="logo"><strong>Editorial</strong> by HTML5 UP</a> -->
									<ul class="icons">
										<!-- <li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon brands fa-snapchat-ghost"><span class="label">Snapchat</span></a></li> -->
										<li><a href="https://www.linkedin.com/in/ying-liu-4b45a8195/" class="icon brands fa-linkedin" style="font-size:1.5em"><span class="label">LinkedIn</span></a></li>
										<li><a href="https://github.com/yingliu1206" class="icon brands fa-github" style="font-size:1.5em"><span class="label">GitHub</span></a></li>
									</ul>
								</header>

							<!-- Content -->
								<section>
                                    <div class="container">
                                        <h1>Statistics</h1>                                      
                                        
                                        <div class="section">
                                            <h2>Statistics Measures</h2>
                                            <ul class="compact-list">
                                                <li><strong>Mean:</strong> The mean is a measure of central tendency, calculated as the sum of all values divided by the number of values. It can be significantly influenced by extremely high or low values in the dataset.</li>
                                                <li><strong>Median:</strong> The median represents the middle value when the data is sorted in ascending order. It is less affected by outliers compared to the mean.</li>
                                                <li><strong>Mode:</strong> The mode is the value that appears most frequently in the dataset.</li>
                                                <li><strong>Outliers:</strong> Outliers are values that differ significantly from other observations. In a normal distribution, outliers are often defined as values that fall outside the range of <span class="highlight">Q3 + 1.5 * IQR</span> or <span class="highlight">Q1 - 1.5 * IQR</span>.</li>
                                                <li>
                                                    <strong>Z-Score:</strong>
                                                    A z-score measures exactly how many standard deviations above or below the mean a data point is. We can determine thresholds (e.g., 2, 2.5, 3) to decide on outliers.
                                                    <ul>
                                                        <li>Z-scores can be applied to all distributions, not just normal distributions.</li>
                                                    </ul>
                                                </li>
                                                <li><strong>Interquartile Range (IQR):</strong> The IQR is the range between the first quartile (Q1) and the third quartile (Q3), encompassing the middle 50% of the data. It helps in identifying the spread and detecting outliers.</li>
                                                <!-- Visual Representation -->
                                                <div class="image-container">
                                                    <img src="images/IQR.png" alt="IQR">
                                                </div>
                                                
                                            </ul>
                                        </div>
                                        
                                        <div class="section">
                                            <h2>Visualizations</h2>
                                            <ul>
                                                <li><strong>Categorical Data:</strong> bar charts and two-way tables.</li>
                                                <li><strong>Histograms:</strong> A histogram displays numerical data by grouping it into bins of equal width. Each bin's height corresponds to the number of data points within that bin. Bins are also referred to as intervals, classes, or buckets.</li>
                                                <li><strong>Stem and Leaf Plots:</strong> This plot displays numerical data by splitting each data point into a leaf (usually the last digit) and a stem (the leading digit or digits).</li>
                                                <li><strong>Box Plot:</strong> A box plot shows the minimum, maximum, median, and interquartile range (IQR) of the data.</li>
                                                <li><strong>Line Graph:</strong> A line graph is useful for showing trends over time. It's important to be cautious about the scale used in the graph.</li>
                                                <li><strong>Scatterplot:</strong> Shows the relationship between two numerical variables. There is no standard rule for identifying outliers, but scatterplots are useful for visualizing correlations.</li>
                                                <li><strong>Cumulative Relative Frequency Graph:</strong> The Y-axis represents percentiles, showing the cumulative distribution of the data.</li>
                                                <div class="image-container">
                                                    <img src="images/cumulative relative frequency plot.png" alt="Cumulative Relative Frequency Graph">
                                                </div>
                                            </ul>
                                        </div>

                                        <div class="section">
                                            <h2>Sampling and Distributions</h2>
                                            <ul class="compact-list">
                                                <li>
                                                    <strong>Sampling:</strong> Selecting a subset from a population to estimate characteristics. Sampling methods can be:
                                                    <ul >
                                                        <li><strong>Probability-based:</strong> Each member of the population has a known probability of being selected.</li>
                                                        <li><strong>Non-probability based:</strong> Selection of individuals is based on convenience, judgment, or quota.</li>
                                                    </ul>
                                                </li>

                                                <li>
                                                    <strong>Distribution:</strong> Refers to the center and spread (variability) of data. When analyzing distributions, consider:
                                                    <ul>
                                                        <li><strong>Center:</strong> Typically described by the <strong>mean</strong> or <strong>median</strong>.</li>
                                                        <li><strong>Spread/Variability:</strong> Described by measures like the <strong>standard deviation (SD)</strong> or the <strong>interquartile range (IQR)</strong>.</li>
                                                        <li>
                                                            <strong>Shift:</strong> When adding a constant to each data point:
                                                            <ul>
                                                                <li><strong>Mean</strong> and <strong>median</strong> will change by the same constant.</li>
                                                                <li><strong>Standard deviation (SD)</strong> and <strong>interquartile range (IQR)</strong> will remain unchanged.</li>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            <strong>Scale:</strong> When multiplying each data point by a constant:
                                                            <ul>
                                                                <li><strong>Mean</strong>, <strong>median</strong>, <strong>SD</strong>, and <strong>IQR</strong> will all change by the same multiplication factor.</li>
                                                            </ul>
                                                        </li>
                                                        <div class="image-container">
                                                            <img src="images/density curve.png" alt="density curve">
                                                        </div>
                                                    </ul>
                                                </li>

                                                <li>
                                                    <strong>Central Limit Theorem:</strong> 
                                                    The central limit theorem states that if a random sample is drawn from any population, regardless of its distribution, <strong>the distribution of the sample means</strong> will be approximately normally distributed as the sample size increases.
                                                    <ul>
                                                        <li>This allows for inferences about a population based on a sample, even without knowing the population's distribution.</li>
                                                        <li>By using the central limit theorem, we can assume that the sample means will be normally distributed and use this information to perform hypothesis tests or construct confidence intervals.</li>
                                                    </ul>
                                                </li>

                                                <li>
                                                    <strong>Combining Random Variables:</strong>
                                                    <ul>
                                                        <li>
                                                            <strong>Effect on Mean and Variance:</strong>
                                                            When combining random variables, those that follow a normal distribution, the resulting distribution also follows a normal distribution. Here's how the mean, standard deviation, and variance are affected:
                                                            <div class="image-container">
                                                                <img src="images/combining random variables.png" alt="combining random variables">
                                                            </div>
                                                        </li>
                                                    </ul>
                                                </li>


                                                <li>
                                                    <strong>Normal Distribution:</strong> A type of probability distribution commonly observed in real-world phenomena such as heights, weights, or IQ scores.
                                                    <ul>
                                                        <li>Also known as a <strong>Gaussian distribution</strong> or a <strong>bell curve</strong> due to its shape.</li>
                                                        <li>The bell curve is defined by the <strong>mean</strong> and the <strong>standard deviation</strong>.</li>
                                                        <li>The <strong>68-95-99.7 rule</strong> explains the proportion of data that falls within specific standard deviations:
                                                            <ul>
                                                                <li>68% of the data are within one standard deviation of the mean.</li>
                                                                <li>95% of the data are within two standard deviations of the mean.</li>
                                                                <li>99.7% of the data are within three standard deviations of the mean.</li>
                                                            </ul>
                                                            <div class="image-container">
                                                                <img src="images/normal distribution.png" alt="normal distribution">
                                                            </div>
                                                        </li>
                                                    </ul>
                                                </li>

                                                <li>
                                                    <strong>Binomial Distribution:</strong>
                                                    <ul>
                                                        <li>
                                                            A binomial distribution describes the number of successes in a fixed number of independent trials of a binary (yes/no) experiment, each with the same probability of success.
                                                        </li>
                                                        <li>
                                                            <strong>Binomial Variable:</strong>
                                                            <div class="image-container">
                                                                <img src="images/binomial vairables.png" alt="Binomial Variables">
                                                            </div>
                                                        </li>
                                                        <li>
                                                            <strong>Probability Mass Function:</strong> The probability of getting exactly \( k \) successes in \( n \) trials is given by:
                                                            <br>
                                                            \( P(X = k) = C(n, k) \cdot p^k \cdot (1 - p)^{(n - k)} \)
                                                            <br>
                                                            where:
                                                            <ul>
                                                                <li>\( C(n, k) \) is the binomial coefficient (combinations).</li>
                                                                <li>\( p \) is the probability of success on a single trial.</li>
                                                                <li>\( n \) is the number of trials.</li>
                                                                <li>\( k \) is the number of successes.</li>
                                                                <li>Example:</li>
                                                                <div class="image-container">
                                                                    <img src="images/binomial distribution example.png" alt="Binomial Distribution Example">
                                                                </div>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            <strong>Mean and Variance:</strong>
                                                            <ul>
                                                                <li><strong>Mean:</strong> \( \mu = n \cdot p \)</li>
                                                                <li><strong>Variance:</strong> \( \sigma^2 = n \cdot p \cdot (1 - p) \)</li>
                                                            </ul>
                                                        </li>
                                                    </ul>
                                                </li>

                                                <li>
                                                    <strong>Bernoulli Distribution:</strong>
                                                    <ul>
                                                        <li>A Bernoulli distribution is a special case of the binomial distribution where the number of trials \( n \) is 1.</li>
                                                        <li>
                                                            <strong>Probability Mass Function:</strong> The probability of success in a single Bernoulli trial is given by:
                                                            <br>
                                                            \( P(X = 1) = p \)
                                                            <br>
                                                            \( P(X = 0) = 1 - p \)
                                                            <br>
                                                            where:
                                                            <ul>
                                                                <li>\( p \) is the probability of success.</li>
                                                                <li>\( 1 - p \) is the probability of failure.</li>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            <strong>Mean and Variance:</strong>
                                                            <ul>
                                                                <li><strong>Mean:</strong> \( \mu = p \)</li>
                                                                <li><strong>Variance:</strong> \( \sigma^2 = p \cdot (1 - p) \)</li>
                                                            </ul>
                                                        </li>
                                                    </ul>
                                                </li>

                                                <li>
                                                    <strong><span class="highlight">Using Population to Estimate Sample Characteristics:</span></strong>
                                                    <ul>
                                                        <ol>
                                                            <li>
                                                                <strong>Sample Proportion Distribution:</strong>
                                                                <ul>
                                                                    <li>The distribution of sample proportions is approximately normal if:
                                                                        <ul>
                                                                            <li>The expected number of successes and failures is at least 10 (i.e., &#1109;p &#8805; 10 and &#1109;(1 - p) &#8805; 10).</li>
                                                                            <li>The sample size is ≤ 10% of the population, or sampling is done with replacement to ensure independence.</li>
                                                                        </ul>
                                                                    </li>
                                                                    <li>Sample Mean = \( p \) (the population proportion)</li>
                                                                    <li>Sample Variance = \( \frac{p \cdot (1 - p)}{n} \)</li>
                                                                </ul>
                                                            </li>
                                                            <li>
                                                                <strong>Sample Mean Distribution:</strong>
                                                                <ul>
                                                                    <li>The distribution of sample means is approximately normal if:
                                                                        <ul>
                                                                            <li>The sample size is sufficiently large (≥ 30). For smaller sample sizes (< 30), the distribution approximates the population distribution if the population distribution is normal.</li>
                                                                        </ul>
                                                                    </li>
                                                                    <li>Sample Mean = &#956; (the population mean) .</li>
                                                                    <li>Sample Variance = &#966;&#8322;/n (where &#966;&#8322; is the population variance).</li>
                                                                </ul>
                                                            </li>
                                                            <li>
                                                                <strong>Example:</strong>
                                                                <div class="image-container">
                                                                    <img src="images/population_sample_example.png" alt="Population to Sample Example">
                                                                </div>
                                                            </li>
                                                        </ol>
                                                    </ul>
                                                </li>
                                                
                                        </div>
                                    
                                        <div class="section">
                                            <h2>Inference and Testing</h2>
                                            <ul class="compact-list">
                                                <li>
                                                    <strong>Confidence Intervals:</strong> A range within which a population parameter is likely to fall.
                                                    <ul>
                                                        <li>
                                                            <strong>Confidence Interval for Means (n ≥ 30): <span class="highlight">\( \bar{x} \pm z \cdot \frac{\sigma}{\sqrt{n}} \)</span></strong>
                                                            where:
                                                            <ul>
                                                                <li>\(\bar{x}\) is the sample mean.</li>
                                                                <li>\(z\) is the z-score corresponding to the desired confidence level.</li>
                                                                <li>\(\sigma\) is the population standard deviation (or sample standard deviation if \(\sigma\) is unknown).</li>
                                                                <li>\(n\) is the sample size.</li>
                                                            </ul>
                                                            <ul>
                                                                <li>
                                                                    <strong>Conditions for Inference on a Mean:</strong>
                                                                    <ul>
                                                                        <li><strong>Random:</strong> A random sample or randomized experiment should be used to obtain the data.</li>
                                                                        <li><strong>Normal:</strong> The sampling distribution of the sample mean needs to be approximately normal. This is true if:
                                                                            <ul>
                                                                                <li>The parent population is normal,</li>
                                                                                <li>or the sample size is reasonably large (n ≥ 30),</li>
                                                                                <li>or the sample distribution is roughly symmetric with no outliers.</li>
                                                                            </ul>
                                                                        </li>
                                                                        <li><strong>Independent:</strong>If sampling without replacement, the sample size should be less than 10% of the population.</li>
                                                                    </ul>
                                                                </li>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            <strong>Confidence Interval for Means (n < 30): <span class="highlight">\( \bar{x} \pm t \cdot \frac{s}{\sqrt{n}} \)</span></strong>
                                                            where:
                                                            <ul>
                                                                <li>\(\bar{x}\) is the sample mean.</li>
                                                                <li>\(t\) is the t-score from the t-distribution corresponding to the desired confidence level and degrees of freedom (\(n-1\)).</li>
                                                                <li>\(s\) is the sample standard deviation.</li>
                                                                <li>\(n\) is the sample size.</li>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            <strong>Confidence Interval for Proportions: <span class="highlight">\( \hat{p} \pm z \cdot \sqrt{\frac{\hat{p} \cdot (1 - \hat{p})}{n}} \)</span></strong>
                                                            where:
                                                            <ul>
                                                                <li>\(\hat{p}\) is the sample proportion.</li>
                                                                <li>\(z\) is the z-score corresponding to the desired confidence level.</li>
                                                                <li>\(n\) is the sample size.</li>
                                                            </ul>
                                                            <ul>
                                                                <li>
                                                                    <strong>Conditions for Inference on a Proportion:</strong>
                                                                    <ul>
                                                                        <li><strong>Random:</strong> The data needs to come from a random sample or randomized experiment.</li>
                                                                        <li><strong>Normal:</strong> At least 10 expected successes and 10 expected failures.</li>
                                                                        <li><strong>Independent:</strong> If sampling without replacement, the sample size should be less than 10% of the population.</li>
                                                                    </ul>
                                                                </li>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            <strong>Confidence Interval for the Mean Difference of Paired Data: <span class="highlight">\( \bar{d} \pm t \cdot \frac{s_d}{\sqrt{n}} \)</span></strong>
                                                            where:
                                                            <ul>
                                                                <li>\(\bar{d}\) is the mean difference between paired observations.</li>
                                                                <li>\(t\) is the t-score from the t-distribution corresponding to the desired confidence level and degrees of freedom (\(n-1\)).</li>
                                                                <li>\(s_d\) is the sample standard deviation of the differences.</li>
                                                                <li>\(n\) is the number of paired observations.</li>
                                                            </ul>
                                                        </li>
                                                    </ul>
                                                </li>
                                                
                                                <li><strong>Z Statistic vs T Statistic:</strong> The number of standard errors is used to calculate the statistic based on the confidence level. The Z statistic is used for large sample sizes or known population standard deviation, while the T statistic is used for smaller samples or unknown population standard deviation.</li>
                                                <ul>
                                                    <li><strong>Z Statistic:</strong> 
                                                        <span class="highlight">\( Z = \frac{\bar{x} - \mu}{\frac{\sigma}{\sqrt{n}}} \)</span>
                                                        <ul>
                                                            <li>\(\bar{x}\) is the sample mean.</li>
                                                            <li>\(\mu\) is the population mean.</li>
                                                            <li>\(\sigma\) is the population standard deviation.</li>
                                                            <li>\(n\) is the sample size.</li>
                                                        </ul>
                                                    </li>
                                                    <li><strong>T Statistic:</strong> 
                                                        <span class="highlight">\( T = \frac{\bar{x} - \mu}{\frac{s}{\sqrt{n}}} \) (\(df = n - 1\))</span>
                                                        <ul>
                                                            <li>\(\bar{x}\) is the sample mean.</li>
                                                            <li>\(\mu\) is the population mean.</li>
                                                            <li>\(s\) is the sample standard deviation.</li>
                                                            <li>\(n\) is the sample size.</li>
                                                        </ul>
                                                    </li>
                                                    <li><strong>Selection:</strong> 
                                                        <div class="image-container">
                                                            <img src="images/Test-statistic.png" alt="Test Statistic">
                                                        </div>
                                                    </li>
                                                </ul>
                                                
                                                <li>
                                                    <strong>Hypothesis Testing:</strong>
                                                    <ul>
                                                        <li>
                                                            Hypothesis testing is a method in which a sample dataset is compared against the population data. <strong><span class="highlight">Using Sample to Estimate Population Characteristics:</span></strong>
                                                        </li>
                                                        <li>
                                                            <strong>Steps for performing a hypothesis test:</strong>
                                                            <ul>
                                                                <li>
                                                                    <strong>State your null and alternative hypotheses:</strong> The null hypothesis (H<sub>0</sub>) generally assumes no change, while the alternative hypothesis (H<sub>a</sub>) suggests a deviation from the null hypothesis.
                                                                </li>
                                                                <li>
                                                                    <strong>Set your significance level (α):</strong> Typically set at 5% (α = 0.05), but it can vary depending on the severity of Type I (false positive) and Type II (false negative) errors in the situation.
                                                                </li>
                                                                <li>
                                                                    <strong>Collect sample data and calculate sample statistics:</strong> Use the Z-statistic or T-statistic based on the sample size and distribution of the data.
                                                                </li>
                                                                <li>
                                                                    <strong>Calculate the p-value:</strong> The p-value is derived from the sample statistics and indicates the likelihood of observing the data under the null hypothesis. Common approaches are based on T-scores and Z-scores for normal distributions.
                                                                </li>
                                                                <li>
                                                                    <strong>Make a decision:</strong> Based on the p-value, reject or do not reject the null hypothesis. If the p-value is less than the significance level, reject the null hypothesis.
                                                                </li>
                                                                <li>
                                                                    <strong>Statistical Significance:</strong> 
                                                                    <ul>
                                                                        <li>If \( P < \alpha \), then the result is considered statistically significant.</li>
                                                                    </ul>
                                                                </li>
                                                            </ul>
                                                        </li>
                                                        <li>
                                                            <strong>Type I and Type II Errors:</strong>
                                                            <ul>
                                                                <li>
                                                                    <strong>Type I Error:</strong> Occurs when we reject the null hypothesis when it is actually true.
                                                                    <ul>
                                                                        <li>Also known as a "false positive."</li>
                                                                        <li>The probability of making a Type I error is denoted by alpha (α), which is the significance level of the test.</li>
                                                                    </ul>
                                                                </li>
                                                                <li>
                                                                    <strong>Type II Error:</strong> Occurs when we fail to reject the null hypothesis when it is actually false.
                                                                    <ul>
                                                                        <li>Also known as a "false negative."</li>
                                                                        <li>The probability of making a Type II error is denoted by beta (β).</li>
                                                                    </ul>
                                                                </li>
                                                            </ul>
                                                        </li>
                                                        
                                                        <li>
                                                            <strong>Power of a Test:</strong>
                                                            <ul>
                                                                <li>Power = P(not making a Type II error)</li>
                                                                <li>
                                                                    A higher power reduces the likelihood of committing a Type II error (failing to reject a false null hypothesis).
                                                                </li>
                                                                <li>
                                                                    <strong>Methods to increase power:</strong>
                                                                    <ul>
                                                                        <li>Increase the sample size.</li>
                                                                        <li>Increase the significance level α. <em>(Note: this may increase the risk of a Type I error)</em></li>
                                                                        <li>Reduce variability in the data (control experimental conditions).</li>
                                                                        <li>Choose a larger effect size (the difference between the null and alternative hypotheses).</li>
                                                                    </ul>
                                                                </li>
                                                            </ul>
                                                        </li>

                                                        <li>
                                                            <strong>Example 1:</strong> Calculating the Z test and p-value for a proportion:
                                                            <div class="image-container">
                                                                <img src="images/z test example.png" alt="Z test example">
                                                            </div>
                                                        </li>
                                                        
                                                        <li>
                                                            <strong>Example 2:</strong> Calculating the t test and p-value for a mean:
                                                            <div class="image-container">
                                                                <img src="images/t test example.png" alt="T test example">
                                                            </div>
                                                        </li>
                                                        
                                                        <li>
                                                            <strong>Example 3:</strong> Two-sample inference for the difference between groups:
                                                            <ul>
                                                                <li>Mean of Sample 1: <em>mean<sub>P1</sub></em>, Variance of Sample 1: <em>var<sub>P1</sub></em></li>
                                                                <li>Mean of Sample 2: <em>mean<sub>P2</sub></em>, Variance of Sample 2: <em>var<sub>P2</sub></em></li>
                                                                <li>Mean of the Difference: \( \text{mean}_{\text{diff}} = \text{mean}_{\text{P1}} - \text{mean}_{\text{P2}} \)</li>
                                                                <li>Variance of the Difference: \( \text{var}_{\text{diff}} = \text{var}_{\text{P1}} + \text{var}_{\text{P2}} \)</li>
                                                            </ul>
                                                            <div class="image-container">
                                                                <img src="images/two-sample1.png" alt="Two-sample inference for the difference between groups">
                                                                <img src="images/two-sample2.png" alt="Two-sample inference for the difference between groups">
                                                            </div>
                                                            <div class="image-container">
                                                                <img src="images/two-sample3.png" alt="Two-sample inference for the difference between groups">
                                                                <img src="images/two-sample4.png" alt="Two-sample inference for the difference between groups">
                                                            </div>
                                                            <div class="image-container">
                                                                <img src="images/two-sample5.png" alt="Two-sample inference for the difference between groups">
                                                                <img src="images/two-sample6.png" alt="Two-sample inference for the difference between groups">
                                                            </div>
                                                        </li>                                   

                                                    </ul>
                                                </li>

                                                <li><strong>Chi-Square Testing</strong>
                                                    <ul>
                                                        <li>
                                                            <strong>Chi-Square Distribution:</strong>
                                                            A chi-square statistic measures the difference between observed and expected frequencies in categorical variables. It is useful for analyzing differences in nominal categorical variables.
                                                            <div class="example">
                                                                <strong>Example Probability:</strong>
                                                                <code>P(Q<sub>2</sub> &gt; 2.41) = 0.3</code>
                                                                <div class="image-container">
                                                                    <img src="images/chi-square distribution.png" alt="Chi-Square Distribution">
                                                                    <img src="images/chi-square distribution2.png" alt="Chi-Square Distribution">
                                                                </div>
                                                            </div>
                                                            
                                                        </li>

                                                        <li><strong>Conditions for Inference:</strong>
                                                            <ul>
                                                                <li><strong>Random:</strong> A random sample or randomized experiment should be used to obtain the data.</li>
                                                                <li><strong>Normal:</strong> The expected number of each category outcome should be ≥ 5.</li>
                                                                <li><strong>Independent:</strong> The sample size should be less than 10% of the population if sampling without replacement.</li>
                                                            </ul>
                                                        </li>

                                                        <li><strong>Types of Chi-Square Tests:</strong>
                                                            <ul>
                                                                <ol>
                                                                    <li><strong>Pearson's Chi-Square Test (Goodness of Fit):</strong> Assesses how well the observed frequencies fit the expected frequencies.</li>
                                                                    <ul>
                                                                        <li>
                                                                            <div class="example">
                                                                                <strong>Example:</strong>
                                                                                <div class="image-container">
                                                                                    <img src="images/pearson's chi-square.png" alt="Design a Chi-Square Test">
                                                                                </div>
                                                                            </div>                                                            
                                                                        </li> 
                                                                    </ul>
                                                                    <li><strong>Test for Association (Independence):</strong> Evaluates the association between two variables within the same population.</li>
                                                                    <ul>
                                                                        <li>
                                                                            <div class="example">
                                                                                <strong>Example:</strong><br>
                                                                                - Sample: Measure foot and hand length in the same population<br>
                                                                                - Hypotheses:<br>
                                                                                - <code>H<sub>0</sub></code>: No association between foot and hand length (independent).<br>
                                                                                - <code>H<sub>a</sub></code>: There is an association.</p>
                                                                                <div class="image-container">
                                                                                    <img src="images/chi-square-association.png" alt="Chi-Square Test for Association">
                                                                                </div>
                                                                            </div>                                                            
                                                                        </li> 
                                                                    </ul>
                                                                    <li><strong>Test for Homogeneity:</strong> Compares distributions across different populations.</li>
                                                                    <ul>
                                                                        <li>
                                                                            <div class="example">
                                                                                <strong>Example:</strong><br>
                                                                                - Sample: 20 left-handed and 30 right-handed individuals<br>
                                                                                - Hypotheses:<br>
                                                                                - <code>H<sub>0</sub></code>: No difference in subject preference between left and right-handed individuals.<br>
                                                                                - <code>H<sub>a</sub></code>: There is a difference.</p>
                                                                                <div class="image-container">
                                                                                    <img src="images/chi-square-homo.png" alt="Chi-Square Test for Homogeneity">
                                                                                </div>
                                                                            </div>                                                            
                                                                        </li> 
                                                                    </ul>
                                                                </ol>
                                                            </ul>
                                                        </li>

                                                        <li>
                                                            <strong>Filling out frequency table for independent events</strong>
                                                            <div class="image-container">
                                                                <img src="images/fill_out_frequency_table.png" alt="Filling out frequency tablefor independent events">
                                                            </div>
                                                        </li>
                                                        
                                                        <li>
                                                            <strong>Degrees of Freedom:</strong>
                                                            <p><code>Degrees of Freedom = (Number of Columns - 1) × (Number of Rows - 1)</code></p>
                                                        </li>

                                                    </ul>
                                                </li>

                                                <li><strong>ANOVA (Analysis of Variance):</strong> Compares means of three or more groups to determine significant differences.</li>
                                                <ul>
                                                    <li>
                                                        <div class="example">
                                                            <strong>Example 1: Testing Food Preferences</strong><br>
                                                            Let's say we want to test if three different types of food (1, 2, and 3) have different effects on a preference score. We have the following:<br>
                                                            <ul>
                                                                <li><strong>M:</strong> Number of groups (3)</li>
                                                                <li><strong>N:</strong> Number of elements in each group</li>
                                                            </ul>

                                                            <ul>
                                                                <ol>
                                                                    <li>
                                                                        <strong>Calculate SST (Total Sum of Squares)</strong><br>
                                                                                Degrees of freedom: <code>M*N - 1</code>
                                                                                <div class="image-container">
                                                                                    <img src="images/anova1.png" alt="Testing Food Preferences">
                                                                                </div>
                                                                    </li>

                                                                    <li>
                                                                        <strong>Calculate SSW (Sum of Squares Within) and SSB (Sum of Squares Between)</strong><br>
                                                                                Figure out how much SST is caused by the variance within the group and between the groups:
                                                                                <ul>
                                                                                    <li><strong>SSW:</strong> Sum of squares within the group, Degrees of freedom: <code>M*(N-1)</code></li>
                                                                                    <li><strong>SSB:</strong> Sum of squares between the groups, Degrees of freedom: <code>M-1</code></li>
                                                                                </ul>
                                                                                <div class="image-container">
                                                                                    <img src="images/anova-ssw.png" alt="Testing Food Preferences">
                                                                                    <img src="images/anova-ssb.png" alt="Testing Food Preferences">
                                                                                </div>
                                                                    </li>

                                                                    <li>
                                                                        <strong>According to the formula: <code>SST = SSW + SSB</code></strong><br>
                                                                        <div class="image-container">
                                                                            <img src="images/anova-sst.png" alt="Testing Food Preferences">
                                                                        </div>
                                                                    </li>

                                                                    <li><strong>Hypothesis test:</strong> 
                                                                        <ul>
                                                                            <li><code>H<sub>0</sub></code>: Food does not make a difference: <code>μ1 = μ2 = μ3</code></li>
                                                                            <li><code>H<sub>a</sub></code>: There is a difference</li>
                                                                            <li><strong>α:</strong> 0.10</li>
                                                                        </ul>
                                                                    </li>

                                                                    <li><strong>Calculate the F-statistic:</strong> 
                                                                        <div class="image-container">
                                                                            <img src="images/anova-F.png" alt="Testing Food Preferences">
                                                                        </div>
                                                                        <ul>
                                                                            <li>If the numerator is larger (variance between groups is larger), <code>H<sub>a</sub></code> is more likely to be true, and <code>F</code> is larger.</li>
                                                                            <li>If the denominator is larger (variance within groups is larger), it is harder to reject <code>H<sub>0</sub></code>, and <code>F</code> is smaller.</li>
                                                                        </ul>
                                                                    </li>

                                                                    <li><strong>Conclusion:</strong> 
                                                                        <div class="image-container">
                                                                            <img src="images/anova-f2.png" alt="Testing Food Preferences">
                                                                        </div>
                                                                        <div class="image-container">
                                                                            <img src="images/anova-f3.png" alt="Testing Food Preferences">
                                                                        </div>
                                                                        <ul>
                                                                            <li>Both the denominator and numerator follow a Chi-square distribution.</li>
                                                                            <li>Suppose the F-statistic calculated is 3.46 and the critical value is 12. We have enough evidence to reject <code>H0</code>.</li>
                                                                        </ul>
                                                                    </li>

                                                                </ol>
                                                            </ul>
                                                        </div>                                                            
                                                    </li> 
                                            
                                                    <li>
                                                        <strong>Example 2: Species Comparison</strong><br>
                                                        <strong>Distribution of Petal Length by Species:</strong><br>
                                                        <p>In this example, we performed an ANOVA test in Python to analyze the differences in the petal length of three different species of iris: setosa, versicolor, and virginica.</p>
                                                        <p>We loaded the iris dataset using the seaborn library, which contains information about the petal length, width, and other variables for each species of iris. We separated each species' petal length data into three sets: <code>setosa_petal_length</code>, <code>versicolor_petal_length</code>, and <code>virginica_petal_length</code>. The ANOVA test was performed using the <code>f_oneway()</code> function from the <code>scipy.stats</code> library, which provided the F-statistic and p-value.</p>
                                            
                                                        <p><strong>Here is the code:</strong></p>
                                                        <pre><code>from scipy.stats import f_oneway
import seaborn as sns

# load the 'iris' dataset
iris = sns.load_dataset('iris')

# perform the ANOVA test
setosa_petal_length = iris[iris['species'] == 'setosa']['petal_length']
versicolor_petal_length = iris[iris['species'] == 'versicolor']['petal_length']
virginica_petal_length = iris[iris['species'] == 'virginica']['petal_length']

f_statistic, p_value = f_oneway(setosa_petal_length, versicolor_petal_length, virginica_petal_length)

# print the results
print('F-statistic:', f_statistic)
print('p-value:', p_value)</code></pre>
                                            
                                                        <p><strong>Output Example:</strong></p>
                                                        <pre><code>F-statistic: 1180.16
p-value: 2.86e-91</code></pre>
                                                        <p>The resulting F-statistic was 1180.16, indicating a significant difference between the means of the petal length for the three species. The p-value was 2.86e-91, a very small value close to zero, indicating that the probability of observing such a large F-statistic by chance alone is very low. Therefore, we reject the null hypothesis that there is no significant difference between the means of petal length for the three species. We conclude that there is a significant difference between the means of petal length for at least one pair of species.</p>
                                                    </li>
                                                </ul>
                                            </ul>
                                        </div>

                                        <div class="section">
                                            <h2>A/B Testing</h2>
                                            A/B testing is an experiment comparing two variants to determine which performs better based on a given metric. It is essentially a form of two-sample hypothesis testing used to assess whether the differences between two samples are statistically significant.
                                            <ul class="compact-list">
                                                <li>
                                                    <strong>Steps to Conduct an A/B Test:</strong>
                                                    <ul>
                                                        <li>State the null and alternative hypotheses.</li>
                                                        <li>Set the significance level (α).</li>
                                                        <li>Collect sample data and calculate the sample statistics.</li>
                                                        <li>Calculate the p-value according to the type of A/B test.</li>
                                                        <li>Compare the p-value to the significance level to determine whether to reject the null hypothesis.</li>
                                                    </ul>
                                                </li>
                                                <li>
                                                    <strong>Choosing the Right Metric:</strong> The metric should be relevant to the test goal. Common metrics include conversion rate, click-through rate, or revenue.
                                                </li>
                                                <li>
                                                    <strong>Defining Hypotheses:</strong> Clearly specify the null and alternative hypotheses and set the significance level before conducting the test.
                                                </li>
                                                <li>
                                                    <strong>Sample Size Considerations:</strong> The sample size should be large enough to detect a meaningful difference but manageable in terms of cost and time. Factors to consider include expected effect size, significance level, and statistical power.
                                                </li>
                                                <li>
                                                    <strong>Real-Life Applications:</strong> A/B testing can be applied in various scenarios, such as:
                                                    <ul>
                                                        <li>A software company testing two feature versions to measure user engagement.</li>
                                                        <li>A fashion retailer comparing two product descriptions to determine which leads to more sales.</li>
                                                        <li>An e-commerce platform evaluating two checkout processes to see which results in more completed orders.</li>
                                                    </ul>
                                                </li>
                                                <li>
                                                    <strong>In-depth understanding:</strong> <a href="https://towardsdatascience.com/a-b-testing-a-complete-guide-to-statistical-testing-e3f1db140499" target="_blank">Francesco’s article on A/B testing</a>.
                                                </li>
                                                <li>
                                                    <strong>Methods:</strong> 
                                                    <ul>
                                                        <ol>
                                                            <li>
                                                                <strong>Fisher’s Exact Test:</strong> This test is used for discrete metrics like clickthrough rates (1 for yes, 0 for no). It computes the exact p-value, though it can be computationally expensive for large sample sizes.
                                                            
                                                                <div class="example">
                                                                    <strong>Example: Advertising Campaign</strong>
                                                                    <p>Suppose you're a marketing researcher testing a new advertising campaign's effectiveness. You randomly assign website visitors to see either the new or old ads and record their clickthrough rates. Fisher's test can help determine if the new ads are significantly more effective in increasing clickthrough rates compared to the old ads.</p>
                                                                </div>
                                                            </li>
                                                            
                                                            <li>
                                                                <strong>Pearson’s Chi-squared Test:</strong> This test is an alternative to Fisher’s test for <u>large sample sizes</u> and is used for discrete metrics.
                                                                <div class="example">
                                                                    <strong>Example: Marketing Research</strong>
                                                                    <p>Consider a company that wants to explore the relationship between customer age groups (young, middle-aged, elderly) and their preferred product categories (food, clothing, electronics). They collect data from 500 customers and use Pearson's Chi-squared test to see if there is a significant association between age and product preference.</p>
                                                                </div>
                                                            </li>
                                                            
                                                            <li>
                                                                <strong>Student’s t-test:</strong> Used when the <u>sample size is large or the population standard deviation is unknown</u>. Suitable for comparing means when the samples have similar variances.
                                                            
                                                                <div class="example">
                                                                    <strong>Example: Teaching Method Testing</strong>
                                                                    <p>A study comparing the effectiveness of two teaching methods involves two groups of students. Each group receives a different method, and their test scores are compared using Student's t-test to determine if the new method significantly improves scores over the traditional method.</p>
                                                                </div>
                                                            </li>
                                                            
                                                            <li>
                                                                <strong>Welch’s Test:</strong> A variant of the Student’s t-test used when the two samples have <u>unequal variances</u>.
                                                            
                                                                <div class="example">
                                                                    <strong>Example: Salary Testing</strong>
                                                                    <p>To compare salaries between managers and entry-level employees, researchers use Welch’s t-test because the salaries' variability differs between the two groups. This test helps determine if there's a significant salary gap despite the unequal variances.</p>
                                                                </div>
                                                            </li>
                                                            
                                                            <li>
                                                                <strong>Mann-Whitney U Test:</strong> A non-parametric test used when assumptions for other tests (e.g., normality) are violated. Suitable for <u>small sample sizes and non-normal distributions</u>.
                                                            
                                                                <div class="example">
                                                                    <strong>Example: Medication Testing</strong>
                                                                    <p>In a study comparing the effectiveness of two pain medications with non-normally distributed data, the Mann-Whitney U test is used. Patients rate their pain after taking each medication, and the test helps determine if there is a significant difference in pain relief between the two treatments without assuming normality.</p>
                                                                </div>
                                                            </li>
                                                            
                                                            <li>
                                                                <strong>For more details on how to conduct these tests in Python, check out this <a href="https://github.com/FrancescoCasalegno/AB-Testing/blob/main/AB_Testing.ipynb" target="_blank">repository</a>.</strong>
                                                            </li>
                                                        </ol>
                                                    </ul>
                                                </li>

                                            </ul>
                                        </div>
                                    
                                        <div class="section">
                                            <h2>Relationships and Models</h2>
                                            <ul>
                                                <li><strong>Correlation:</strong> Measures the strength and direction of a linear relationship between two variables.</li>
                                                <li><strong>Linear Regression:</strong> Models the relationship between a dependent variable and one or more independent variables.</li>
                                                <li><strong>A/B Testing:</strong> Compares two versions of a variable to determine which performs better.</li>
                                                <li><strong>Cosine Similarity:</strong> Measures similarity between two vectors of an inner product space, often used in text analysis.</li>
                                            </ul>
                                        </div>

                                        <div class="section">
                                            <h2>Probability</h2>
                                            <ul>
                                                <li><strong>Probability Rules:</strong> Basic principles for calculating probabilities.</li>
                                                <li><strong>Bayes Theorem:</strong> Describes the probability of an event based on prior knowledge.</li>
                                                <li><strong>Combinations and Permutations:</strong> Methods for counting and arranging objects.</li>
                                            </ul>
                                        </div>
                                    
                                        <div class="section">
                                            <h2>Advanced Topics</h2>
                                            <ul>
                                                <li><strong>Bayesian Methods:</strong> Statistical methods that involve updating probabilities based on new evidence.</li>
                                            </ul>
                                        </div>
                                        <!-- <li><strong>Population Variance:</strong> Calculated by dividing by N (the number of data points).</li>
                                                <li><strong>Sample Variance:</strong> Calculated by dividing by N-1 to avoid bias.</li>
                                                <li><strong>Mean Absolute Deviation:</strong> Average distance between each data point and the mean.</li>
                                                <li><strong>Z-Score:</strong> Measures how many standard deviations a data point is from the mean.</li>
                                                <li><strong>Mean Shift and Scale:</strong> Adding a constant shifts the mean and median; multiplying scales all measures.</li>
                                                <li><strong>Density Curve:</strong> Represents the distribution of data points.</li>
                                                <li><strong>Normal Distribution (Empirical Rule):</strong> 68% within 1 SD, 95% within 2 SD, 99.7% within 3 SD.</li> -->
                                        
                                                <!-- <div class="section">
                                            <h2>Regression and Correlation</h2>
                                            <ul>
                                                <li><strong>Correlation Coefficient:</strong> Measures the strength and direction of the linear relationship between two variables.</li>
                                                <li><strong>Linear Regression:</strong> Uses a line to summarize the relationship between variables. Key metrics include slope, residuals, and Sum of Squared Residuals (SSR).</li>
                                                <li><strong>R-Squared:</strong> Indicates the percentage of variation in Y explained by X. Calculated as 1 - (SSR/SST).</li>
                                                <li><strong>Root Mean Square Error (RMSD):</strong> Standard deviation of residuals. Lower RMSD indicates a better model.</li>
                                                <li><strong>Residual Plot:</strong> Evaluates the fit of a regression model. Evenly scattered points suggest a good model.</li>
                                            </ul>
                                        </div>
                                
                                        <div class="section">
                                            <h2>Advanced Topics</h2>
                                            <ul>
                                                <li><strong>Combining Random Variables:</strong> When combined, normally distributed variables remain normally distributed.</li>
                                                <li><strong>Binomial Distribution:</strong> Describes the number of successes in a fixed number of trials. The expected value is np and variance is np(1-p).</li>
                                                <li><strong>Central Limit Theorem:</strong> The distribution of sample means approximates a normal distribution as sample size increases.</li>
                                                <li><strong>Confidence Intervals:</strong> Provide a range of plausible values for a population parameter. Calculated using sample means and standard errors.</li>
                                                <li><strong>Significance Tests:</strong> Tests null hypotheses against alternative hypotheses. Calculated using p-values and significance levels (α).</li>
                                                <li><strong>Chi-Square Test:</strong> Measures the difference between observed and expected frequencies. Useful for categorical data analysis.</li>
                                                <li><strong>ANOVA:</strong> Compares means across multiple groups to determine if there are significant differences.</li>
                                            </ul>
                                        </div>

                                       -->

                                        <div class="section">
                                        <h2>Courses Attended</h2>
                                            <h3>Georgetown University (DSAN Program):</h3>
                                            <ul>
                                                <li>Probabilistic Modeling and Statistical Computing</li>
                                                <li>Statistical Learning</li>
                                            </ul>
                                            <h3>Khan Academy:</h3>
                                            <ul>
                                                <li>Statistics and Probability</li>
                                            </ul>
                                        </div>
                                    </div>
                                    
									
								</section>

						</div>
					</div>

                <!-- Sidebar -->
				<div id="sidebar-container"></div>
				
				<script>
					document.addEventListener("DOMContentLoaded", function() {
					  fetch('sidebar.html')
						.then(response => response.text())
						.then(data => {
						  document.getElementById('sidebar-container').innerHTML = data;
			  
						  // Load scripts after sidebar content is added
						  const scripts = [
							'assets/js/jquery.min.js',
							'assets/js/browser.min.js',
							'assets/js/breakpoints.min.js',
							'assets/js/util.js',
							'assets/js/main.js',
							'assets/js/search.js'
						  ];
			  
						  scripts.reduce((promise, script) => {
							return promise.then(() => {
							  return new Promise((resolve, reject) => {
								const s = document.createElement('script');
								s.src = script;
								s.onload = resolve;
								s.onerror = reject;
								document.body.appendChild(s);
							  });
							});
						  }, Promise.resolve())
						  .then(() => {
							console.log('All scripts loaded successfully.');
							// Ensure initialization of search after all scripts are loaded
							if (typeof window.initializeSearch === 'function') {
							  window.initializeSearch();
							}
						  })
						  .catch(error => {
							console.error('Error loading script:', error);
						  });
						})
						.catch(error => console.error('Error loading sidebar:', error));
					});
				</script>	
		</div>	

	</body>
</html>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
